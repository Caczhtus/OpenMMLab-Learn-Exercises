{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb43ab37-1813-4056-8364-34b5accdf55c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-02-09T13:43:06.058588Z",
     "iopub.status.busy": "2023-02-09T13:43:06.058354Z",
     "iopub.status.idle": "2023-02-09T13:43:08.137668Z",
     "shell.execute_reply": "2023-02-09T13:43:08.136593Z",
     "shell.execute_reply.started": "2023-02-09T13:43:06.058562Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_d53_320_273e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             27.9\n",
      "config                                                  configs/yolo/yolov3_d...\n",
      "epochs                                                  273\n",
      "inference_time(ms/im)[V100,PyTorch,1,FP32,(320, 320)]   15.65\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     2.7\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_d53_mstrain-416_273e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             30.9\n",
      "config                                                  configs/yolo/yolov3_d...\n",
      "epochs                                                  273\n",
      "inference_time(ms/im)[V100,PyTorch,1,FP32,(416, 416)]   16.34\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     3.8\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_d53_mstrain-608_273e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             33.7\n",
      "config                                                  configs/yolo/yolov3_d...\n",
      "epochs                                                  273\n",
      "inference_time(ms/im)[V100,PyTorch,1,FP32,(608, 608)]   20.79\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     7.4\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_d53_fp16_mstrain-608_273e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             33.8\n",
      "config                                                  configs/yolo/yolov3_d...\n",
      "epochs                                                  273\n",
      "inference_time(ms/im)[V100,PyTorch,1,FP16,(608, 608)]   20.79\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     4.7\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_mobilenetv2_320_300e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             22.2\n",
      "config                                                  configs/yolo/yolov3_m...\n",
      "epochs                                                  300\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     3.2\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "--------------------------------------------------------------------------------\n",
      "config id: yolov3_mobilenetv2_mstrain-416_300e_coco\n",
      "architecture                                            darknet\n",
      "coco/box_ap                                             23.9\n",
      "config                                                  configs/yolo/yolov3_m...\n",
      "epochs                                                  300\n",
      "model                                                   yolov3\n",
      "paper                                                   URL,Title\n",
      "readme                                                  configs/yolo/README.md\n",
      "training_data                                           coco\n",
      "training_memory(GB)                                     5.3\n",
      "training_resources                                      8x v100 gpus\n",
      "training_techniques                                     sgd with momentum,wei...\n",
      "weight                                                  https://download.open...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mim search mmdet --model \"yolov3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e44fa8-bd88-4257-bc5d-f97585d25a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T13:41:51.828439Z",
     "iopub.status.busy": "2023-02-09T13:41:51.828181Z",
     "iopub.status.idle": "2023-02-09T13:41:56.625094Z",
     "shell.execute_reply": "2023-02-09T13:41:56.623926Z",
     "shell.execute_reply.started": "2023-02-09T13:41:51.828419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing yolov3_mobilenetv2_mstrain-416_300e_coco...\n",
      "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MiB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[32mSuccessfully downloaded yolov3_mobilenetv2_mstrain-416_300e_coco_20210718_010823-f68a07b3.pth to /output/balloon-detection\u001b[0m\n",
      "\u001b[32mSuccessfully dumped yolov3_mobilenetv2_mstrain-416_300e_coco.py to /output/balloon-detection\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mim download mmdet --config yolov3_mobilenetv2_mstrain-416_300e_coco --dest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42044f32-af9e-4832-954a-c9b9b7a563b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-09T14:46:51.358480Z",
     "iopub.status.busy": "2023-02-09T14:46:51.358049Z",
     "iopub.status.idle": "2023-02-09T14:46:52.003223Z",
     "shell.execute_reply": "2023-02-09T14:46:52.002736Z",
     "shell.execute_reply.started": "2023-02-09T14:46:51.358444Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=192)\n",
      "model = dict(\n",
      "    type='YOLOV3',\n",
      "    backbone=dict(\n",
      "        type='MobileNetV2',\n",
      "        out_indices=(2, 4, 6),\n",
      "        act_cfg=dict(type='LeakyReLU', negative_slope=0.1),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='open-mmlab://mmdet/mobilenet_v2')),\n",
      "    neck=dict(\n",
      "        type='YOLOV3Neck',\n",
      "        num_scales=3,\n",
      "        in_channels=[320, 96, 32],\n",
      "        out_channels=[96, 96, 96]),\n",
      "    bbox_head=dict(\n",
      "        type='YOLOV3Head',\n",
      "        num_classes=80,\n",
      "        in_channels=[96, 96, 96],\n",
      "        out_channels=[96, 96, 96],\n",
      "        anchor_generator=dict(\n",
      "            type='YOLOAnchorGenerator',\n",
      "            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n",
      "                        [(30, 61), (62, 45), (59, 119)],\n",
      "                        [(10, 13), (16, 30), (33, 23)]],\n",
      "            strides=[32, 16, 8]),\n",
      "        bbox_coder=dict(type='YOLOBBoxCoder'),\n",
      "        featmap_strides=[32, 16, 8],\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_conf=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_xy=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=2.0,\n",
      "            reduction='sum'),\n",
      "        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='GridAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0)),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        conf_thr=0.005,\n",
      "        nms=dict(type='nms', iou_threshold=0.45),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Expand',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        to_rgb=True,\n",
      "        ratio_range=(1, 2)),\n",
      "    dict(\n",
      "        type='MinIoURandomCrop',\n",
      "        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "        min_crop_size=0.3),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(320, 320), (416, 416)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(416, 416),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=24,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=10,\n",
      "        dataset=dict(\n",
      "            type='CocoDataset',\n",
      "            ann_file='data/coco/annotations/instances_train2017.json',\n",
      "            img_prefix='data/coco/train2017/',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "                dict(\n",
      "                    type='Expand',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    to_rgb=True,\n",
      "                    ratio_range=(1, 2)),\n",
      "                dict(\n",
      "                    type='MinIoURandomCrop',\n",
      "                    min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "                    min_crop_size=0.3),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=[(320, 320), (416, 416)],\n",
      "                    multiscale_mode='range',\n",
      "                    keep_ratio=True),\n",
      "                dict(type='RandomFlip', flip_ratio=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size_divisor=32),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "            ])),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(type='SGD', lr=0.003, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=4000,\n",
      "    warmup_ratio=0.0001,\n",
      "    step=[24, 28])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=30)\n",
      "evaluation = dict(interval=1, metric=['bbox'])\n",
      "find_unused_parameters = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "config = Config.fromfile('yolov3_mobilenetv2_mstrain-416_30e_balloon.py')\n",
    "print(config.pretty_text)  # 把已有的继承进来，再进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dc4ab-df78-4ef1-a45f-e20d68cdfbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
